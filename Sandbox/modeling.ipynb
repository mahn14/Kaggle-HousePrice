{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahn/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/mahn/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "\n",
    "# Data Processing and Exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical Exploration Library\n",
    "import scipy.stats as stats\n",
    "from minepy import MINE\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Modeling\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Self-Implemented\n",
    "import preprocessing as PRE\n",
    "import modeling as MOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahn/Desktop/SandBox/preprocessing.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_missing_num['MasVnrArea']= df_missing_num['MasVnrArea'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "file1 = 'train.csv'\n",
    "file2 = 'test.csv'\n",
    "df = PRE.get_data(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (Grid Search) Set\n",
    "train_i, train_l, a, b = PRE.split_train_test(df, frac=0.33)\n",
    "ab = pd.concat([a, b], axis=1)\n",
    "\n",
    "# Training (Base Models) Set\n",
    "cv_i, cv_l, test_i, test_l = PRE.split_train_test(ab, frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_grid = RandomForestRegressor()\n",
    "params_rf = {'n_estimators':(16, 18, 20, 22, 24), \n",
    "          'min_samples_split':(2, 3, 4, 5, 6)}\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_grid = linear_model.Lasso()\n",
    "params_lasso = {'alpha':(0.00005, 0.0001, 0.0005, 0.05),\n",
    "         'fit_intercept':(True,False),\n",
    "         'normalize':(True,False)}\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_grid = linear_model.Ridge()\n",
    "params_ridge = {'alpha':(0.00005, 0.0001, 0.0005, 0.05),\n",
    "         'fit_intercept':(True,False),\n",
    "         'normalize':(True,False)}\n",
    "\n",
    "# Extreme Gradient Boosting\n",
    "xgboost_grid = xgb.XGBRegressor()\n",
    "params_xgboost = {'max_depth': (2, 3, 4),\n",
    "                  'n_estimators': (100, 125),\n",
    "                  'min_child_weight': (2, 3, 4),\n",
    "                  'learning_rate': (0.1, 0.2)\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Get best hyperparameters for each model\\nrf = MOD.get_params(rf_grid, params_rf, train_i, train_l)\\nlasso = MOD.get_params(lasso_grid, params_lasso, train_i, train_l)\\nridge = MOD.get_params(ridge_grid, params_ridge, train_i, train_l)\\nxgboost =  MOD.get_params(xgboost_grid, params_xgboost, train_i, train_l)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Get best hyperparameters for each model\n",
    "rf = MOD.get_params(rf_grid, params_rf, train_i, train_l)\n",
    "lasso = MOD.get_params(lasso_grid, params_lasso, train_i, train_l)\n",
    "ridge = MOD.get_params(ridge_grid, params_ridge, train_i, train_l)\n",
    "xgboost =  MOD.get_params(xgboost_grid, params_xgboost, train_i, train_l)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rf, lasso, ridge, xgboost) = ({'min_samples_split': 5, 'n_estimators': 22},\n",
    " {'alpha': 5e-05, 'fit_intercept': True, 'normalize': True},\n",
    " {'alpha': 0.0005, 'fit_intercept': False, 'normalize': True},\n",
    " {'learning_rate': 0.1,\n",
    "  'max_depth': 4,\n",
    "  'min_child_weight': 2,\n",
    "  'n_estimators': 125})\n",
    "\n",
    "# Make new models using best hyperparameters\n",
    "rf_base = RandomForestRegressor(**rf)\n",
    "lasso_base = linear_model.Lasso(**lasso)\n",
    "ridge_base = linear_model.Ridge(**ridge)\n",
    "xgboost_base = xgb.XGBRegressor(**xgboost)\n",
    "\n",
    "# Put base models into a list\n",
    "base_models = [rf_base, lasso_base, ridge_base, xgboost_base]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit new base models to training set\n",
    "rf_base.fit(train_i, train_l)\n",
    "lasso_base.fit(train_i, train_l)\n",
    "ridge_base.fit(train_i, train_l)\n",
    "xgboost_base.fit(train_i, train_l)\n",
    "\n",
    "# Predict on training set\n",
    "cv1 = pd.DataFrame(rf_base.predict(cv_i))\n",
    "cv2 = pd.DataFrame(lasso_base.predict(cv_i))\n",
    "cv3 = pd.DataFrame(ridge_base.predict(cv_i))\n",
    "cv4 = pd.DataFrame(xgboost_base.predict(cv_i))\n",
    "\n",
    "# Turn predictions into an \"input\" df for grid search on meta model\n",
    "train_stack = pd.concat([cv1, cv2, cv3, cv4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.0005, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = linear_model.Ridge(**ridge)\n",
    "meta_model.fit(train_stack, cv_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on testing set\n",
    "test1 = pd.DataFrame(rf_base.predict(test_i))\n",
    "test2 = pd.DataFrame(lasso_base.predict(test_i))\n",
    "test3 = pd.DataFrame(ridge_base.predict(test_i))\n",
    "test4 = pd.DataFrame(xgboost_base.predict(test_i))\n",
    "\n",
    "# Turn predictions into an \"input\" df for final testing on meta model\n",
    "test_stack = pd.concat([test1,test2,test3, test4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16116750674362815,\n",
       " 0.14527243398219661,\n",
       " 0.1517558757389291,\n",
       " 0.13251927673851879]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForest, Lasso, Ridge final tests\n",
    "[MOD.score_final(model, test_i, test_l) for model in base_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13335923505065383"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meta Model (Ridge) final test\n",
    "MOD.score_final(meta_model, test_stack, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdf = PRE.get_df('train.csv')\n",
    "\n",
    "\ttrain = True\n",
    "\ttest = False\n",
    "\tif 'SalePrice' not in list(df.columns):\n",
    "\t\ttest = True\n",
    "\t\ttrain = False\n",
    "\n",
    "\t# Drop features missing more than 10% of rows\n",
    "\tdrop = df.isnull().sum()/df.shape[0]\n",
    "\tdrop_list = list(drop[drop > 0.1].index)\n",
    "\tdf = df.drop(drop_list, axis=1)\n",
    "\n",
    "\t# Separate remaining features with missing rows from df\n",
    "\tkeep = df.isnull().sum() / df.shape[0]\n",
    "\tkeep_list = keep[keep > 0].index \n",
    "\tdf_missing = df[keep_list]\n",
    "\tdf = df.drop(keep_list, axis=1)\n",
    "\n",
    "\t# Label continuous (num) columns\n",
    "\tif train:\n",
    "\t\tnum = ['GarageYrBlt', 'MasVnrArea']\n",
    "\telse:\n",
    "\t\tnum = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'GarageArea', 'GarageCars', 'GarageYrBlt', 'TotalBsmtSF', 'MasVnrArea']\n",
    "\n",
    "\t# Label categorical (cat) columns\n",
    "\tcat = []\n",
    "\tfor i in  df_missing.columns:\n",
    "\t    if i not in num:\n",
    "\t        cat.append(i)\n",
    "\n",
    "\t# Separate cont and cat \n",
    "\tdf_missing_num = df_missing[num]\n",
    "\tdf_missing_cat = df_missing[cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MasVnrType',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Electrical',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
